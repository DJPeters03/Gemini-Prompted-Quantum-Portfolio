Quantum AI Agents — Learning Inside Quantum Worlds

This folder is where quantum mechanics stops being passive and becomes interactive, adversarial, and adaptive.

Unlike classical AI demos, the agents here:
	•	Exist in superposition
	•	Collapse under measurement
	•	Compete inside quantum-style environments
	•	Learn using probability, interference, and reward

Core theme:
Intelligence emerges when probability is forced to decide.

⸻

What This Folder Demonstrates

This section explores three ideas at once:
	1.	Quantum-inspired environments
	2.	Multi-agent competition and survival
	3.	Learning under uncertainty

Each file is intentionally framed as a game, because games expose behavior.

⸻

File Order & Conceptual Flow

1. QuantumBattleRoyale.html

Measurement as Elimination

100 qubits enter superposition simultaneously.

Each round:
	•	All qubits fluctuate between |0⟩ and |1⟩
	•	A global measurement collapses the system
	•	Only qubits measured as |1⟩ survive

This continues until one qubit remains.

Key takeaway:

Survival can be driven purely by measurement.

￼

⸻

2. QuditSpinner.html

Continuous Decision Spaces

This simulation replaces binary qubits with multi-state qudits.

You see:
	•	A continuously rotating hazard
	•	A qudit choosing one of many angular states
	•	Survival depends on timing and positioning, not fixed states

Key takeaway:

Higher-dimensional state spaces allow richer behavior.

￼

⸻

3. ElectronBattle.html

Energy, Emission, and Elimination

Atoms battle using real quantum rules:
	•	Electrons gain energy (excitation)
	•	Energy drops emit photons
	•	High-energy photons ionize opponents

No health bars.
No hit points.
Only quantum transitions.

Key takeaway:

Energy level changes are actions.

￼

⸻

4. QuditBattleRoyale.html

Dimensional Survival

100 qudits choose dimensions to occupy.

Round 1:
	•	All qudits pick a dimension
	•	The most populated dimension survives

Round 2:
	•	Survivors redistribute into a new dimensional grid
	•	Only isolated qudits persist

Key takeaway:

Coordination and isolation both matter — depending on the phase.

￼

⸻

5. EntanglementSimulator.html

Learning to Entangle

Two qubit agents repeatedly choose gates.

Rules:
	•	Only certain gate combinations create entanglement
	•	Successful entanglement yields reward
	•	Agents adapt gate probabilities over time

This is reinforcement learning on quantum rules, not pixels.

Key takeaway:

Entanglement can be learned.

￼

⸻

6. QuantumMaze.html

Superposition-Based Navigation

A single agent navigates a procedurally generated maze.

At each step:
	•	The agent explores multiple paths in superposition
	•	Paths interfere constructively or destructively
	•	Memory stores “bad” paths as destructive interference

Key takeaway:

Exploration does not need randomness — it needs interference.

￼

⸻

How This Folder Connects Backward

From Quantum Computing, we learned:
	•	How to represent states
	•	How to apply gates
	•	How measurement works

This folder asks:

“What happens when agents live inside those rules?”

⸻

How This Folder Connects Forward

This section naturally leads to:
	•	Hybrid quantum-classical learning
	•	Quantum reinforcement learning
	•	Swarm intelligence with entanglement
	•	Adaptive quantum simulations

➡️ This is the frontier of quantum + AI.